## Grepping flaws from the given project list.
# Merging output generated by FlawFinder and CppCheck
## Grepping functions from the vulnerability context of the file.
# file, function and statement-level information

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import lizard
import subprocess as sub
from pylibsrcml import srcml
import os
import xml.etree.ElementTree as et
import sys
import csv
import requests
from io import BytesIO, StringIO
import numpy as np
import itertools
import tempfile
from zipfile import ZipFile
from guesslang import Guess

# add parent dir to access modules
# sys.path.append("../")

from src.tools import apply_flawfinder, apply_cppcheck, apply_rats

pl_list = ["C", "C++"]


def concat(*args):
    """merge two columns of the dataframw with numpy vectorize method"""
    strs = [str(arg) for arg in args if not pd.isnull(arg)]
    return ",".join(strs) if strs else np.nan


def function_metrics(source_file, lines, cwes, tool="cppcheck"):
    """split the given file into a list of function blocks and return their metrics into a dataframe"""
    # lines = [eval(l) for l in lines]  # python default casting to integer
    df = pd.DataFrame()

    with open(source_file, "r") as fp:
        liz_file = lizard.analyze_file.analyze_source_code(source_file, fp.read())

        for ifun in range(len(liz_file.function_list)):
            fun_metrics = liz_file.function_list[ifun].__dict__
            df_fun = pd.DataFrame.from_dict(fun_metrics)

            start = int(fun_metrics["start_line"])
            end = int(fun_metrics["end_line"])
            fp.seek(0)  # move header to the initial point of the file

            vul_content = ""
            vul_statements = []
            cwe = []
            vul_bool = False

            # check if any of the lines of the file belong to any functions
            for index, (l, c) in enumerate(zip(lines, cwes)):
                fun_block = [line for line in itertools.islice(fp, start, end)]
                fp.seek(0)
                df_fun["code"] = fun_metrics["long_name"] + "".join(fun_block)

                # check if the vulnerability content/statement appear in the function block or not.
                # For 'is_vul' equals  True
                if start <= l <= end:
                    if tool == "cppcheck":
                        # option 1
                        vul_content = fun_block[l - start]
                        vul_statements.append(vul_content)
                        fp.seek(0)

                        # option 2 - can be removed one if there is no error at the end
                        vul_stat2 = fp.readlines()[l]

                        assert (
                            vul_stat2 == vul_content
                        ), "Cross-check why two vul statements are different!"
                        fp.seek(0)
                    else:
                        # ToDo: take actual Context from FlawFinder's result
                        vul_content = df_flaw[df_flaw.line == l]["Context"].values[0]

                    cwe.append(c)

                df_fun["fun_name"] = fun_metrics["name"]
                df_fun["content"] = (
                    str(vul_statements) if len(vul_statements) > 0 else ""
                )
                df_fun["is_vul"] = True if cwe else False

                # In case of Rats tool the 'unknown-vul' is list, make it one item only.
                cwe = list(set(cwe))

                if len(cwe) > 0:
                    # df_fun['cwe'] = 'unknown'  if np.isnan(cwe).all() else str(cwe)
                    df_fun["cwe"] = "unknown" if all(i != i for i in cwe) else str(cwe)
                else:
                    df_fun["cwe"] = "benign"

            df = pd.concat([df, df_fun])

    # <guru> I think there is a problem in lizard detecting the correct full_parameters
    # either we have to concatenate two lines of full_parameters or ignore it and take it from long_name if needed.
    # drop['full_parameters', 'fan_in', 'fan_out', 'general_fan_out'] because lizard has not properly
    # implemented these parameters yet.

    cols_filter = [
        "full_parameters",
        "fan_in",
        "fan_out",
        "general_fan_out",
        "top_nesting_level",
    ]
    df = df.drop_duplicates().reset_index(drop=True)

    if set(cols_filter).issubset(set(list(df.columns))):
        df = df.drop(cols_filter, axis=1)
    return df


def merge_flawfinder_cppcheck(df_ff, df_cc, df_rat):
    """merge dataframe generated by FlawFinder and CppCheck tools"""
    common_cols = ["file", "line", "column", "cwe", "note"]
    unique_cols = ["context", "defaultlevel", "level", "helpuri"]
    filter_cols = [
        "toolversion",
        "fingerprint",
        "ruleid",
        "suggestion",
        "defaultlevel",
        "level",
    ]
    ## Adjusting columns generated by FlawFinder tool
    df_ff = df_ff.rename(columns=str.lower)  # lower case
    df_ff = df_ff.rename(columns={"cwes": "cwe", "warning": "msg"})

    ## Adjusting columns generated by CppCheck tool
    df_cc = df_cc.rename(columns={"info": "note", "id": "name"})

    ## Adjusting columns generated by CppCheck tool
    df_rat = df_rat.rename(columns={"message": "msg", "type": "category"})

    ## cppcheck: As we checked, 'msg' and 'verbose' columns have same entries,
    ## so let's keep only 'msg'.
    df_cc = (
        df_cc.drop(columns=["verbose"]) if "verbose" in list(df_cc.columns) else df_cc
    )

    # To make CWE column values uniform to FlawFinder output
    df_cc["cwe"] = "CWE-" + df_cc["cwe"]

    np_concat = np.vectorize(concat)
    df_ff["note"] = np_concat(df_ff["suggestion"], df_ff["note"])
    # do this after merging 'suggestion to 'note' column
    df_ff = df_ff.drop(columns=filter_cols)
    return pd.concat([df_ff, df_cc, df_rat])


# # TBD: Function Under Construction:
# def srcML_funs(file):
#     """find function blocks of the given file using srcML"""
#     fun_ptn = "string(//src:function)"
#     funblk_ptn = "string((//src:function/src:name))"
#     # file_ptn = "string(//src:unit/@filename)"

#     # cmd = sub.Popen(["srcml", "--xpath", fun_ptn, file], stderr=sub.STDOUT)
#     # out, err = cmd.communicate()
#     cmd = ["srcml", "--xpath", funblk_ptn, xml_file]
#     process = sub.Popen(cmd, stderr=sub.STDOUT)
#     return process


def guess_pl(file, zip_obj=None):
    """guess programming language of the input file."""
    guess = Guess()
    if zip_obj is not None:
        # extract a specific file from the zip container
        with zip_obj.open(file, "r") as f:
            lang = guess.language_name(f.read())
    else:
        with open(file, "r", encoding="unicode_escape") as f:
            lang = guess.language_name(f.read())
    return lang


def project_flaws(df):
    """find flaw entries of all the complete project scanning each unique file."""
    df_prj = pd.DataFrame()

    for f in list(set(df.file)):  # on every unique files
        lines = list(df[df.file == f]["line"])
        cwes = list(df[df.file == f]["cwe"])
        # vul_statements = list(df_flaw[df_flaw.file==x]['cwe'])
        # lines = [x[0] if len(x) == 1 else [x[0], x[1]] for x in lines]

        # TODO: check if any of the entries has multiple locations or lines
        # lines = [x[0] if len(x) == 1 else [x[0], x[1]] for x in lines]
        df_file = function_metrics(f, lines, cwes, tool="cppcheck")
        df_prj = pd.concat([df_prj, df_file])

    return df_prj.reset_index(drop=True).drop_duplicates()


def file2df(file, zip_obj=None):
    """convert zipped file stream - tempfile to pandas dataframe."""
    file_content = ""
    df_flaw = pd.DataFrame()
    df_metrics = pd.DataFrame()

    if zip_obj:
        # io.StringIO(sf.read().decode("utf-8")).read()
        with zip_obj.open(file) as fc:
            # file_content = fc.read().encode('UTF-8')
            file_content = fc.read()
    else:
        with open(file) as fc:
            file_content = fc.read().encode("utf-8")

    fp = tempfile.NamedTemporaryFile(suffix="_Flawfinder", prefix="Filename_")

    # deal with the temp file of extracted zipped file
    try:
        fp.write(file_content)
        fp.seek(0)  # move reader's head to the initial point of the file.
        file_name = fp.name
        df_flaw = apply_flawfinder(file_or_dir=file_name)
        print(df_flaw)

        df_metrics = function_metrics(source_file=file_name, df_flaw=df_flaw)
        print(f"Shape of the found flaws data of the file: {df_flaw.shape}")
        print(f"Shape of the file flaws metrics: {df_metrics.shape}")

    except OSError:
        print("Could not open/read file:", fp)
        sys.exit(1)
    finally:
        fp.close()
    return df_flaw, df_metrics


def check_internet(url):
    response = requests.get(url)
    return True if response.status_code < 400 else False


def retrieve_zip(url):
    """Fetching list of C/C++ files from zip file of the project url."""
    if check_internet(url):
        r = requests.get(url)
        # BytesIO keeps the file in memory
        return ZipFile(BytesIO(r.content))
    else:
        print("Internet is not working!")
        return None


def urlzip2df(url):
    """concatenate all the output dataframes of all the files"""
    print("=" * 35)
    print(
        "Generating composite dataframe from the given project URL of zip file...\n",
        url,
    )
    print("=" * 35)

    zipobj = retrieve_zip(url)
    files = zipobj.namelist()
    selected_files = [x for x in files if guess_pl(x, zipobj) in pl_list]

    if selected_files:
        df_flaw_prj = pd.DataFrame()
        df_metrics_prj = pd.DataFrame()

        for i in range(len(selected_files)):
            df_flaw_file, df_metrics_file = file2df(selected_files[i], zipobj)
            df_flaw_prj = pd.concat([df_flaw_prj, df_flaw_file])
            df_metrics_prj = pd.concat([df_metrics_prj, df_metrics_file])

        print("Shape of the FlawFinder data of the project:", df_flaw_prj.shape)
        print("Shape of the function level metrics of prj:", df_metrics_prj.shape)
        return df_flaw_prj.reset_index(drop=True), df_metrics_prj.reset_index(drop=True)
    else:
        print(f"No file in the specified project  by the given PL: {pl_list}")
        return None, None


if __name__ == "__main__":
    # # # CppCheck scaning a dir
    # chk_dir = "data/projects/contiki-2.4/apps/"

    # df_ff = apply_flawfinder(chk_dir)
    # df_cc = apply_cppcheck(chk_dir)

    # df_flaw = merge_flawfinder_cppcheck(df_ff, df_cc)
    # df_fun = project_flaws(df_flaw)

    # Example prj: The list of the URL links of the project zip files.
    # TODO create a file of list of projects
    prj_dir_urls = [
        "https://sourceforge.net/projects/contiki/files/Contiki/Contiki%202.4/contiki-sky-2.4.zip/download",
        "data/projects/contiki-2.4/apps/",
    ]
    df_flaw = pd.DataFrame()
    df_metrics = pd.DataFrame()

    # iterate on every project:
    for prj in prj_dir_urls:
        df_prj, df_prj_met = urlzip2df(prj)
        df_flaw = pd.concat([df_flaw, df_prj])
        df_metrices = pd.concat([df_metrices, df_prj_met])

    if len(df_flaw) > 0 and len(df_metrics) > 0:
        df_flaw.to_csv("data/contiki24_flaw.csv")
        df_metrics.to_csv("data/contiki24_metrics.csv")
    else:
        print("The given project URL does not have any specified files to analyze!")
