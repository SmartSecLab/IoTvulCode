## Grepping flaws from the given project list.
# Merging output generated by FlawFinder and CppCheck

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import lizard
import subprocess as sub
from pylibsrcml import srcml
import os
import xml.etree.ElementTree as et
import sys
import csv

# from lxml import etree
import pandas as pd
import subprocess as sub
import sys
from io import BytesIO, StringIO
import numpy as np
import itertools

# add parent dir to access modules
# sys.path.append("../")

from src.flawfinder import apply_flawfinder
from src.cppcheck import xml2df, apply_cppcheck


def concat(*args):
    """merge two columns of the dataframw with numpy vectorize method"""
    strs = [str(arg) for arg in args if not pd.isnull(arg)]
    return ",".join(strs) if strs else np.nan


def function_metrics(source_file, lines, cwes, tool="cppcheck"):
    """split the given file into a list of function blocks and return their metrics into a dataframe"""
    # lines = [eval(l) for l in lines]  # python default casting to integer
    df = pd.DataFrame()

    with open(source_file, "r") as fp:
        liz_file = lizard.analyze_file.analyze_source_code(source_file, fp.read())

        for ifun in range(len(liz_file.function_list)):
            fun_metrics = liz_file.function_list[ifun].__dict__
            df_fun = pd.DataFrame.from_dict(fun_metrics)

            start = int(fun_metrics["start_line"])
            end = int(fun_metrics["end_line"])
            fp.seek(0)  # move header to the initial point of the file

            vul_content = ""
            vul_statements = []
            cwe = []
            vul_bool = False

            # check if any of the lines of the file belong to any functions
            for index, (l, c) in enumerate(zip(lines, cwes)):
                fun_block = [line for line in itertools.islice(fp, start, end)]
                fp.seek(0)
                df_fun["code"] = fun_metrics["long_name"] + "".join(fun_block)

                # check if the vulnerability content/statement appear in the function block or not.
                # For 'is_vul' equals  True
                if start <= l <= end:
                    if tool == "cppcheck":
                        # option 1
                        vul_content = fun_block[l - start]
                        vul_statements.append(vul_content)
                        fp.seek(0)

                        # option 2 - can be removed one if there is no error at the end
                        vul_stat2 = fp.readlines()[l]

                        assert (
                            vul_stat2 == vul_content
                        ), "Cross-check why two vul statements are different!"
                        fp.seek(0)
                    else:
                        # ToDo: take actual Context from FlawFinder's result
                        vul_content = df_flaw[df_flaw.line == l]["Context"].values[0]

                    cwe.append(c)

                df_fun["fun_name"] = fun_metrics["name"]
                df_fun["content"] = (
                    str(vul_statements) if len(vul_statements) > 0 else ""
                )
                df_fun["is_vul"] = True if cwe else False

                if len(cwe) > 0:
                    # df_fun['cwe'] = 'unknown'  if np.isnan(cwe).all() else str(cwe)
                    df_fun["cwe"] = "unknown" if all(i != i for i in cwe) else str(cwe)
                else:
                    df_fun["cwe"] = "benign"

            df = pd.concat([df, df_fun])

    # <guru> I think there is a problem in lizard detecting the correct full_parameters
    # either we have to concatenate two lines of full_parameters or ignore it and take it from long_name if needed.
    # drop['full_parameters', 'fan_in', 'fan_out', 'general_fan_out'] because lizard has not properly
    # implemented these parameters yet.

    cols_filter = [
        "full_parameters",
        "fan_in",
        "fan_out",
        "general_fan_out",
        "top_nesting_level",
    ]
    df = df.drop(cols_filter, axis=1).drop_duplicates().reset_index(drop=True)
    return df


def merge_flawfinder_cppcheck(df_ff, df_cc):
    """merge dataframe generated by FlawFinder and CppCheck tools"""
    common_cols = ["file", "line", "column", "cwe", "note"]
    unique_cols = ["context", "defaultlevel", "level", "helpuri"]
    filter_cols = [
        "toolversion",
        "fingerprint",
        "ruleid",
        "suggestion",
        "defaultlevel",
        "level",
    ]
    ## Adjusting columns generated by FlawFinder tool
    df_ff = df_ff.rename(columns=str.lower)  # lower case
    df_ff = df_ff.rename(columns={"cwes": "cwe", "warning": "msg"})

    ## Adjusting columns generated by CppCheck tool
    df_cc = df_cc.rename(columns={"info": "note", "id": "name"})
    # cppcheck: As we checked, 'msg' and 'verbose' columns have same entries, so let's keep only 'msg'.
    df_cc = (
        df_cc.drop(columns=["verbose"]) if "verbose" in list(df_cc.columns) else df_cc
    )
    # To make CWE column values uniform to FlawFinder output
    df_cc["cwe"] = "CWE-" + df_cc["cwe"]

    np_concat = np.vectorize(concat)
    df_ff["note"] = np_concat(df_ff["suggestion"], df_ff["note"])
    # do this after merging 'suggestion to 'note' column
    df_ff = df_ff.drop(columns=filter_cols)
    return pd.concat([df_ff, df_cc])


def project_flaws(df):
    """find flaw entries of all the complete project scanning each unique file."""
    df_prj = pd.DataFrame()

    for f in list(set(df.file)):  # on every unique files
        lines = list(df[df.file == f]["line"])
        cwes = list(df[df.file == f]["cwe"])
        # vul_statements = list(df_flaw[df_flaw.file==x]['cwe'])
        # lines = [x[0] if len(x) == 1 else [x[0], x[1]] for x in lines]

        # TODO: check if any of the entries has multiple locations or lines
        # lines = [x[0] if len(x) == 1 else [x[0], x[1]] for x in lines]

        print("lines: ", lines)
        df_file = function_metrics(f, lines, cwes, tool="cppcheck")
        df_prj = pd.concat([df_prj, df_file])

    return df_prj.reset_index(drop=True).drop_duplicates()


if __name__ == "__main__":
    # # CppCheck scaning a dir
    chk_dir = "data/projects/contiki-2.4/apps/"

    df_ff = apply_flawfinder(chk_dir)
    df_cc = apply_cppcheck(chk_dir)

    df_flaw = merge_flawfinder_cppcheck(df_ff, df_cc)
    df_fun = project_flaws(df_flaw)
