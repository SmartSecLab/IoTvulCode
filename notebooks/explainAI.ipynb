{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explainable-AI model on iDetect dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re, os\n",
    "from string import printable\n",
    "from sklearn import model_selection\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential, Model, model_from_json, load_model\n",
    "from keras import regularizers\n",
    "from keras.layers.core import Dense, Dropout, Activation, Lambda, Flatten\n",
    "from keras.layers import Input, ELU, LSTM, Embedding, Convolution2D, MaxPooling2D, \\\n",
    "BatchNormalization, Convolution1D, MaxPooling1D, concatenate\n",
    "from keras.preprocessing import sequence\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "from pathlib import Path\n",
    "import json\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Bidirectional, SimpleRNN\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "import seaborn as sns\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "# from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.pipeline import TransformerMixin\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "# <guru> Newly added API calls\n",
    "from keras.utils import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>isMalicious</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>( strlen ( me )</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>*pBuffer = MQTT_PACKET_TYPE_CONNECT ; pBuffer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>*pBuffer1 = MQTT_PACKET_TYPE_CONNECT1 ; pBuff...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                code  isMalicious\n",
       "0                                   ( strlen ( me )             1\n",
       "1   *pBuffer = MQTT_PACKET_TYPE_CONNECT ; pBuffer...            1\n",
       "2   *pBuffer1 = MQTT_PACKET_TYPE_CONNECT1 ; pBuff...            1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/iDetect_refine/DNN_Binary.csv', encoding='unicode_escape')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix dimensions of X:  (4720, 150) Vector dimension of target:  (4720,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def tokenize_data(df):\n",
    "    \"\"\" Dataset tokenization\n",
    "    \"\"\"\n",
    "    code_snippet_int_tokens = [[printable.index(x) + 1 for x in code_snippet if x in printable] \n",
    "                            for code_snippet in df.code]\n",
    "    max_len = 150\n",
    "    # X = sequence.pad_sequences(code_snippet_int_tokens, maxlen=max_len) # original\n",
    "    X = pad_sequences(code_snippet_int_tokens, maxlen=max_len)\n",
    "    target = np.array (df.isMalicious)\n",
    "    print('Matrix dimensions of X: ', X.shape, 'Vector dimension of target: ', target.shape)\n",
    "    return X\n",
    "\n",
    "X = tokenize_data(df)\n",
    "#Split the data set into training and test data\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, target, test_size=0.30, random_state=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjsAAAGdCAYAAAD0e7I1AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/P9b71AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAt2klEQVR4nO3df1TUdb7H8RfID0UdCIwZSDQzUxFNr5pOVmuJonKtbnTP2prSXq/evOCmbGaUldktXNfbz0t6t1O6e67kbnuyH2oaYmquaMpqihabZkHFwF5dGLVEge/9o+PcnQQNHGaGj8/HOd9zmO/nM995fz6Kvs73+/l+J8SyLEsAAACGCg10AQAAAG2JsAMAAIxG2AEAAEYj7AAAAKMRdgAAgNEIOwAAwGiEHQAAYDTCDgAAMFpYoAsIBo2Njfrmm2/UtWtXhYSEBLocAADwI1iWpRMnTigxMVGhoc2fvyHsSPrmm2+UlJQU6DIAAEArVFRUqHv37s22E3Ykde3aVdL3k2Wz2QJcDQAA+DHcbreSkpI8/483h7AjeS5d2Ww2wg4AAO3MxZagsEAZAAAYjbADAACMRtgBAABGI+wAAACjEXYAAIDRCDsAAMBohB0AAGA0wg4AADAaYQcAABiNsAMAAIxG2AEAAEYj7AAAAKMRdgAAgNEIOwAAwGhhgS7gcjc2/XZVVh9rsi0hPk6F697xc0UAAJiFsBNgldXHlDJjaZNtpa886OdqAAAwD5exAACA0Qg7AADAaFzGMhRrgQAA+B5hx1CsBQIA4HtcxgIAAEYj7AAAAKMRdgAAgNEIOwAAwGiEHQAAYDTCDgAAMBphBwAAGI2wAwAAjEbYAQAARuMJykHsyy+OKmX4qCbb+MoHAAB+HMJOEGuwQvjKBwAALhGXsQAAgNEIOwAAwGiEHQAAYLSAhp1ly5Zp0KBBstlsstlscjqdeu+99zzto0ePVkhIiNd2//33ex2jvLxc6enpioqKUnx8vObNm6f6+np/DwUAAASpgC5Q7t69uxYvXqw+ffrIsiz99re/1R133KG9e/dqwIABkqQZM2Zo0aJFnvdERUV5fm5oaFB6erocDod27NihyspKTZs2TeHh4XrmmWf8Ph4AABB8Ahp2Jk2a5PX66aef1rJly7Rz505P2ImKipLD4Wjy/e+//74OHTqkTZs2yW63a/DgwXrqqac0f/58LVy4UBEREW0+BgAAENyCZs1OQ0ODVq9erVOnTsnpdHr2r1q1St26dVNKSopyc3P17bffetqKi4s1cOBA2e12z760tDS53W4dPHiw2c+qq6uT2+322gAAgJkC/pydAwcOyOl06vTp0+rSpYvWrFmj5ORkSdLPfvYz9ezZU4mJidq/f7/mz5+vsrIyvfnmm5Ikl8vlFXQkeV67XK5mPzMvL09PPvlkG40IAAAEk4CHnb59+2rfvn2qra3VH//4R2VmZmrr1q1KTk7WzJkzPf0GDhyohIQEjRkzRkeOHFHv3r1b/Zm5ubnKycnxvHa73UpKSrqkcQAAgOAU8MtYERERuvbaazV06FDl5eXp+uuv1wsvvNBk3xEjRkiSDh8+LElyOByqqqry6nPudXPrfCQpMjLScwfYuQ0AAJgp4GHnhxobG1VXV9dk2759+yRJCQkJkiSn06kDBw6ourra06ewsFA2m81zKQwAAFzeAnoZKzc3VxMmTFCPHj104sQJFRQUaMuWLdq4caOOHDmigoICTZw4UXFxcdq/f7/mzp2rW265RYMGDZIkjRs3TsnJyZo6daqWLFkil8ulBQsWKCsrS5GRkYEcGgAACBIBDTvV1dWaNm2aKisrFR0drUGDBmnjxo0aO3asKioqtGnTJj3//PM6deqUkpKSlJGRoQULFnje36FDB61du1azZs2S0+lU586dlZmZ6fVcHgAAcHkLaNh59dVXm21LSkrS1q1bL3qMnj17av369b4sCwAAGCTgd2Ohdb784qhSho9qtr28okIpfqwHAIBgRdhppxqsEKXMWNps++eP3O3HagAACF5BdzcWAACALxF2AACA0biMhRYZm367KquPNdmWEB+nwnXv+LkiAAAujLCDFqmsPtbsWqHSVx70czUAAFwcl7EAAIDRCDsAAMBoXMbCeS60Lofn9wAA2hvCDs5zoXU5PL8HANDecBkLAAAYjbADAACMRtgBAABGI+wAAACjEXYAAIDRCDsAAMBohB0AAGA0wg4AADAaYQcAABiNsAMAAIxG2AEAAEYj7AAAAKMRdgAAgNEIOwAAwGiEHQAAYDTCDgAAMBphBwAAGI2wAwAAjEbYAQAARiPsAAAAoxF2AACA0Qg7AADAaIQdAABgNMIOAAAwGmEHAAAYjbADAACMFtCws2zZMg0aNEg2m002m01Op1Pvvfeep/306dPKyspSXFycunTpooyMDFVVVXkdo7y8XOnp6YqKilJ8fLzmzZun+vp6fw+lXfnyi6NKGT6q2a28oiLQJQIA4DNhgfzw7t27a/HixerTp48sy9Jvf/tb3XHHHdq7d68GDBiguXPnat26dXrjjTcUHR2t7Oxs3XXXXfrTn/4kSWpoaFB6erocDod27NihyspKTZs2TeHh4XrmmWcCObSg1mCFKGXG0mbbP3/kbj9WAwBA2wpo2Jk0aZLX66efflrLli3Tzp071b17d7366qsqKCjQbbfdJklasWKF+vfvr507d2rkyJF6//33dejQIW3atEl2u12DBw/WU089pfnz52vhwoWKiIgIxLAAAEAQCZo1Ow0NDVq9erVOnTolp9OpkpISnT17VqmpqZ4+/fr1U48ePVRcXCxJKi4u1sCBA2W32z190tLS5Ha7dfDgwWY/q66uTm6322sDAABmCnjYOXDggLp06aLIyEjdf//9WrNmjZKTk+VyuRQREaGYmBiv/na7XS6XS5Lkcrm8gs659nNtzcnLy1N0dLRnS0pK8u2gAABA0Ah42Onbt6/27dunXbt2adasWcrMzNShQ4fa9DNzc3NVW1vr2SpYkAsAgLECumZHkiIiInTttddKkoYOHardu3frhRde0E9/+lOdOXNGNTU1Xmd3qqqq5HA4JEkOh0MfffSR1/HO3a11rk9TIiMjFRkZ6eORAACAYBTwMzs/1NjYqLq6Og0dOlTh4eEqKirytJWVlam8vFxOp1OS5HQ6deDAAVVXV3v6FBYWymazKTk52e+1AwCA4BPQMzu5ubmaMGGCevTooRMnTqigoEBbtmzRxo0bFR0drenTpysnJ0exsbGy2WyaPXu2nE6nRo4cKUkaN26ckpOTNXXqVC1ZskQul0sLFixQVlYWZ24AAICkAIed6upqTZs2TZWVlYqOjtagQYO0ceNGjR07VpL03HPPKTQ0VBkZGaqrq1NaWppefvllz/s7dOigtWvXatasWXI6nercubMyMzO1aNGiQA0JAAAEmYCGnVdfffWC7R07dlR+fr7y8/Ob7dOzZ0+tX7/e16UBAABDBN2aHQAAAF8i7AAAAKMRdgAAgNEIOwAAwGiEHQAAYDTCDgAAMBphBwAAGI2wAwAAjEbYAQAARiPsAAAAoxF2AACA0Qg7AADAaIQdAABgNMIOAAAwGmEHAAAYjbADAACMRtgBAABGI+wAAACjEXYAAIDRCDsAAMBohB0AAGA0wg4AADAaYQcAABiNsAMAAIxG2AEAAEYj7AAAAKMRdgAAgNEIOwAAwGhhgS7AdGPTb1dl9bFm28srKpTix3oAALjcEHbaWGX1MaXMWNps++eP3O3HagAAuPxwGQsAABiNsAMAAIxG2AEAAEYj7AAAAKMRdgAAgNECGnby8vI0fPhwde3aVfHx8brzzjtVVlbm1Wf06NEKCQnx2u6//36vPuXl5UpPT1dUVJTi4+M1b9481dfX+3MoAAAgSAX01vOtW7cqKytLw4cPV319vR555BGNGzdOhw4dUufOnT39ZsyYoUWLFnleR0VFeX5uaGhQenq6HA6HduzYocrKSk2bNk3h4eF65pln/DoeAAAQfAIadjZs2OD1euXKlYqPj1dJSYluueUWz/6oqCg5HI4mj/H+++/r0KFD2rRpk+x2uwYPHqynnnpK8+fP18KFCxUREdGmYwAAAMEtqNbs1NbWSpJiY2O99q9atUrdunVTSkqKcnNz9e2333raiouLNXDgQNntds++tLQ0ud1uHTx40D+FAwCAoBU0T1BubGzUnDlzNGrUKKWk/P8XKPzsZz9Tz549lZiYqP3792v+/PkqKyvTm2++KUlyuVxeQUeS57XL5Wrys+rq6lRXV+d57Xa7fT0cAAAQJIIm7GRlZam0tFTbt2/32j9z5kzPzwMHDlRCQoLGjBmjI0eOqHfv3q36rLy8PD355JOXVC8AAGgfguIyVnZ2ttauXasPPvhA3bt3v2DfESNGSJIOHz4sSXI4HKqqqvLqc+51c+t8cnNzVVtb69kqKioudQgAACBIBTTsWJal7OxsrVmzRps3b1avXr0u+p59+/ZJkhISEiRJTqdTBw4cUHV1tadPYWGhbDabkpOTmzxGZGSkbDab1wYAAMwU0MtYWVlZKigo0Ntvv62uXbt61thER0erU6dOOnLkiAoKCjRx4kTFxcVp//79mjt3rm655RYNGjRIkjRu3DglJydr6tSpWrJkiVwulxYsWKCsrCxFRkYGcngAACAIBPTMzrJly1RbW6vRo0crISHBs/3+97+XJEVERGjTpk0aN26c+vXrp1/+8pfKyMjQu+++6zlGhw4dtHbtWnXo0EFOp1P33nuvpk2b5vVcHgAAcPkK6Jkdy7Iu2J6UlKStW7de9Dg9e/bU+vXrfVUW2sjY9NtVWX2sybaE+DgVrnvHzxUBAC4HQXM3FsxXWX1MKTOWNtlW+sqDfq4GAHC5CIq7sQAAANoKYQcAABiNsAMAAIxG2AEAAEYj7AAAAKMRdgAAgNEIOwAAwGiEHQAAYDTCDgAAMBphBwAAGI2wAwAAjEbYAQAARiPsAAAAoxF2AACA0Qg7AADAaIQdAABgNMIOAAAwGmEHAAAYjbADAACMRtgBAABGI+wAAACjEXYAAIDRCDsAAMBohB0AAGC0VoWda665RseOHTtvf01Nja655ppLLgoAAMBXwlrzpi+++EINDQ3n7a+rq9PXX399yUUBLTE2/XZVVp8fviUpIT5Oheve8XNFAIBg0qKw8847//+fxsaNGxUdHe153dDQoKKiIl199dU+Kw74MSqrjyllxtIm20pfedDP1QAAgk2Lws6dd94pSQoJCVFmZqZXW3h4uK6++mr953/+p8+KAwAAuFQtCjuNjY2SpF69emn37t3q1q1bmxQFAADgK61as3P06FFf1wEAANAmWhV2JKmoqEhFRUWqrq72nPE557XXXrvkwgAAAHyhVWHnySef1KJFizRs2DAlJCQoJCTE13WhHfryi6NKGT6q2fbyigql+LEeAACkVoad5cuXa+XKlZo6daqv60E71mCFNHtXlCR9/sjdfqwGAIDvteqhgmfOnNGNN97o61oAAAB8rlVh51//9V9VUFDg61oAAAB8rlVh5/Tp03r22Wf1k5/8RLNnz1ZOTo7X9mPl5eVp+PDh6tq1q+Lj43XnnXeqrKzsvM/KyspSXFycunTpooyMDFVVVXn1KS8vV3p6uqKiohQfH6958+apvr6+NUMDAACGadWanf3792vw4MGSpNLSUq+2lixW3rp1q7KysjR8+HDV19frkUce0bhx43To0CF17txZkjR37lytW7dOb7zxhqKjo5Wdna277rpLf/rTnyR9/+Tm9PR0ORwO7dixQ5WVlZo2bZrCw8P1zDPPtGZ4AADAIK0KOx988IFPPnzDhg1er1euXKn4+HiVlJTolltuUW1trV599VUVFBTotttukyStWLFC/fv3186dOzVy5Ei9//77OnTokDZt2iS73a7Bgwfrqaee0vz587Vw4UJFRET4pFYAANA+teoyVlupra2VJMXGxkqSSkpKdPbsWaWmpnr69OvXTz169FBxcbEkqbi4WAMHDpTdbvf0SUtLk9vt1sGDB/1YPQAACEatOrNz6623XvBy1ebNm1t8zMbGRs2ZM0ejRo1SSsr3T2NxuVyKiIhQTEyMV1+73S6Xy+Xp8/dB51z7ubam1NXVqa6uzvPa7Xa3uF741sWe0cO3lwMAWqtVYefcep1zzp49q3379qm0tPS8Lwj9sbKyslRaWqrt27e36v0tkZeXpyeffLLNPwc/3sWe0cO3lwMAWqtVYee5555rcv/ChQt18uTJFh8vOztba9eu1bZt29S9e3fPfofDoTNnzqimpsbr7E5VVZUcDoenz0cffeR1vHN3a53r80O5ubled4253W4lJSW1uG4AABD8fLpm5957723R92JZlqXs7GytWbNGmzdvVq9evbzahw4dqvDwcBUVFXn2lZWVqby8XE6nU5LkdDp14MABVVdXe/oUFhbKZrMpOTm5yc+NjIyUzWbz2gAAgJla/UWgTSkuLlbHjh1/dP+srCwVFBTo7bffVteuXT1rbKKjo9WpUydFR0dr+vTpysnJUWxsrGw2m2bPni2n06mRI0dKksaNG6fk5GRNnTpVS5Yskcvl0oIFC5SVlaXIyEhfDg8AALRDrQo7d911l9dry7JUWVmpPXv26LHHHvvRx1m2bJkkafTo0V77V6xYofvuu0/S95fMQkNDlZGRobq6OqWlpenll1/29O3QoYPWrl2rWbNmyel0qnPnzsrMzNSiRYtaMzQAAGCYVoWd6Ohor9ehoaHq27evFi1apHHjxv3o41iWddE+HTt2VH5+vvLz85vt07NnT61fv/5Hfy4AALh8tCrsrFixwtd1AAAAtIlLWrNTUlKiTz75RJI0YMAADRkyxCdFAQAA+Eqrwk51dbUmT56sLVu2eG4Jr6mp0a233qrVq1fryiuv9GWNAAAArdaqW89nz56tEydO6ODBgzp+/LiOHz+u0tJSud1u/eIXv/B1jQAAAK3WqjM7GzZs0KZNm9S/f3/PvuTkZOXn57dogTIAAEBba9WZncbGRoWHh5+3Pzw8XI2NjZdcFAAAgK+0KuzcdttteuCBB/TNN9949n399deaO3euxowZ47PiAAAALlWrws5//dd/ye126+qrr1bv3r3Vu3dv9erVS263Wy+99JKvawQAAGi1Vq3ZSUpK0p///Gdt2rRJn376qSSpf//+Sk1N9WlxAAAAl6pFZ3Y2b96s5ORkud1uhYSEaOzYsZo9e7Zmz56t4cOHa8CAAfrwww/bqlYAAIAWa9GZneeff14zZsxo8lvCo6Oj9W//9m969tlndfPNN/usQECSvvziqFKGj2qyrbyiQil+rgcA0H60KOx8/PHH+tWvftVs+7hx47R06dJLLgr4oQYrRCkzmv679fkjd/u5GgBAe9Kiy1hVVVVN3nJ+TlhYmP76179eclEAAAC+0qKwc9VVV6m0tLTZ9v379yshIeGSiwIAAPCVFoWdiRMn6rHHHtPp06fPa/vuu+/0xBNP6B//8R99VhwAAMClatGanQULFujNN9/Uddddp+zsbPXt21eS9Omnnyo/P18NDQ169NFH26RQAACA1mhR2LHb7dqxY4dmzZql3NxcWZYlSQoJCVFaWpry8/Nlt9vbpFAAAIDWaPFDBXv27Kn169frb3/7mw4fPizLstSnTx9dccUVbVEfEDBj029XZfWxJtsS4uNUuO4dP1cEAGiNVj1BWZKuuOIKDR8+3Je1AEGlsvpYs7e7l77yoJ+rAQC0Vqu+GwsAAKC9IOwAAACjEXYAAIDRCDsAAMBohB0AAGA0wg4AADAaYQcAABiNsAMAAIxG2AEAAEYj7AAAAKMRdgAAgNEIOwAAwGiEHQAAYDTCDgAAMBphBwAAGC0s0AUAbenLL44qZfioZtsT4uNUuO4dP1YEAPA3wg6M1mCFKGXG0mbbS1950I/VAAACIaCXsbZt26ZJkyYpMTFRISEheuutt7za77vvPoWEhHht48eP9+pz/PhxTZkyRTabTTExMZo+fbpOnjzpx1EAAIBgFtCwc+rUKV1//fXKz89vts/48eNVWVnp2V5//XWv9ilTpujgwYMqLCzU2rVrtW3bNs2cObOtSwcAAO1EQC9jTZgwQRMmTLhgn8jISDkcjibbPvnkE23YsEG7d+/WsGHDJEkvvfSSJk6cqKVLlyoxMdHnNQMAgPYl6O/G2rJli+Lj49W3b1/NmjVLx44d87QVFxcrJibGE3QkKTU1VaGhodq1a1ezx6yrq5Pb7fbaAACAmYI67IwfP16/+93vVFRUpF/96lfaunWrJkyYoIaGBkmSy+VSfHy813vCwsIUGxsrl8vV7HHz8vIUHR3t2ZKSktp0HAAAIHCC+m6syZMne34eOHCgBg0apN69e2vLli0aM2ZMq4+bm5urnJwcz2u3203gAQDAUEF9ZueHrrnmGnXr1k2HDx+WJDkcDlVXV3v1qa+v1/Hjx5td5yN9vw7IZrN5bQAAwEztKux89dVXOnbsmBISEiRJTqdTNTU1Kikp8fTZvHmzGhsbNWLEiECVCQAAgkhAL2OdPHnSc5ZGko4ePap9+/YpNjZWsbGxevLJJ5WRkSGHw6EjR47ooYce0rXXXqu0tDRJUv/+/TV+/HjNmDFDy5cv19mzZ5Wdna3JkydzJxYAAJAU4DM7e/bs0ZAhQzRkyBBJUk5OjoYMGaLHH39cHTp00P79+3X77bfruuuu0/Tp0zV06FB9+OGHioyM9Bxj1apV6tevn8aMGaOJEyfqpptu0m9+85tADQkAAASZgJ7ZGT16tCzLarZ948aNFz1GbGysCgoKfFkWAAAwSLtaswMAANBShB0AAGA0wg4AADAaYQcAABgtqJ+gDLS1L784qpTho5psK6+oUIqf6wEA+B5hB5e1BitEKTOWNtn2+SN3+7kaAEBb4DIWAAAwGmEHAAAYjbADAACMRtgBAABGI+wAAACjEXYAAIDRCDsAAMBohB0AAGA0HioItIGx6bersvpYk20J8XEqXPeOnysCgMsXYQdoA5XVx5p9MnPpKw/6uRoAuLxxGQsAABiNsAMAAIxG2AEAAEYj7AAAAKMRdgAAgNEIOwAAwGiEHQAAYDTCDgAAMBphBwAAGI2wAwAAjEbYAQAARiPsAAAAoxF2AACA0Qg7AADAaIQdAABgNMIOAAAwGmEHAAAYjbADAACMRtgBAABGI+wAAACjBTTsbNu2TZMmTVJiYqJCQkL01ltvebVblqXHH39cCQkJ6tSpk1JTU/XZZ5959Tl+/LimTJkim82mmJgYTZ8+XSdPnvTjKAAAQDALaNg5deqUrr/+euXn5zfZvmTJEr344otavny5du3apc6dOystLU2nT5/29JkyZYoOHjyowsJCrV27Vtu2bdPMmTP9NQQAABDkwgL54RMmTNCECROabLMsS88//7wWLFigO+64Q5L0u9/9Tna7XW+99ZYmT56sTz75RBs2bNDu3bs1bNgwSdJLL72kiRMnaunSpUpMTPTbWAAAQHAK2jU7R48elcvlUmpqqmdfdHS0RowYoeLiYklScXGxYmJiPEFHklJTUxUaGqpdu3Y1e+y6ujq53W6vDQAAmClow47L5ZIk2e12r/12u93T5nK5FB8f79UeFham2NhYT5+m5OXlKTo62rMlJSX5uHoAABAsgjbstKXc3FzV1tZ6toqKikCXBAAA2kjQhh2HwyFJqqqq8tpfVVXlaXM4HKqurvZqr6+v1/Hjxz19mhIZGSmbzea1AQAAMwVt2OnVq5ccDoeKioo8+9xut3bt2iWn0ylJcjqdqqmpUUlJiafP5s2b1djYqBEjRvi9ZgAAEHwCejfWyZMndfjwYc/ro0ePat++fYqNjVWPHj00Z84c/cd//If69OmjXr166bHHHlNiYqLuvPNOSVL//v01fvx4zZgxQ8uXL9fZs2eVnZ2tyZMncycWAACQFOCws2fPHt16662e1zk5OZKkzMxMrVy5Ug899JBOnTqlmTNnqqamRjfddJM2bNigjh07et6zatUqZWdna8yYMQoNDVVGRoZefPFFv48FAAAEp4CGndGjR8uyrGbbQ0JCtGjRIi1atKjZPrGxsSooKGiL8gAAgAGCds0OAACALxB2AACA0Qg7AADAaIQdAABgNMIOAAAwGmEHAAAYjbADAACMRtgBAABGI+wAAACjEXYAAIDRCDsAAMBohB0AAGA0wg4AADAaYQcAABiNsAMAAIwWFugCgPboyy+OKmX4qGbbyysqlOLHegAAzSPsAK3QYIUoZcbSZts/f+RuP1YDALgQLmMBAACjEXYAAIDRCDsAAMBohB0AAGA0wg4AADAaYQcAABiNsAMAAIxG2AEAAEYj7AAAAKMRdgAAgNEIOwAAwGiEHQAAYDTCDgAAMBphBwAAGI2wAwAAjEbYAQAARiPsAAAAoxF2AACA0Qg7AADAaEEddhYuXKiQkBCvrV+/fp7206dPKysrS3FxcerSpYsyMjJUVVUVwIoBAECwCeqwI0kDBgxQZWWlZ9u+fbunbe7cuXr33Xf1xhtvaOvWrfrmm2901113BbBaAAAQbMICXcDFhIWFyeFwnLe/trZWr776qgoKCnTbbbdJklasWKH+/ftr586dGjlypL9LBQAAQSjoz+x89tlnSkxM1DXXXKMpU6aovLxcklRSUqKzZ88qNTXV07dfv37q0aOHiouLL3jMuro6ud1urw0AAJgpqMPOiBEjtHLlSm3YsEHLli3T0aNHdfPNN+vEiRNyuVyKiIhQTEyM13vsdrtcLtcFj5uXl6fo6GjPlpSU1IajAAAAgRTUl7EmTJjg+XnQoEEaMWKEevbsqT/84Q/q1KlTq4+bm5urnJwcz2u3203gAQDAUEF9ZueHYmJidN111+nw4cNyOBw6c+aMampqvPpUVVU1ucbn70VGRspms3ltAADATEF9ZueHTp48qSNHjmjq1KkaOnSowsPDVVRUpIyMDElSWVmZysvL5XQ6A1wp4H9j029XZfWxZtsT4uNUuO4dP1YEAMEhqMPOgw8+qEmTJqlnz5765ptv9MQTT6hDhw665557FB0drenTpysnJ0exsbGy2WyaPXu2nE4nd2LhslRZfUwpM5Y22176yoN+rAYAgkdQh52vvvpK99xzj44dO6Yrr7xSN910k3bu3Kkrr7xSkvTcc88pNDRUGRkZqqurU1paml5++eUAVw0AAIJJUIed1atXX7C9Y8eOys/PV35+vp8qAgAA7U27WqAMAADQUoQdAABgNMIOAAAwGmEHAAAYLagXKAMm+vKLo0oZPqrZdp6HAwC+RdgB/KzBCuF5OADgR1zGAgAARuPMDgC+agKA0Qg7APiqCQBG4zIWAAAwGmd2gCBzobu1uJwEAC1H2AGCzIXu1uJyEgC0HJexAACA0Qg7AADAaIQdAABgNMIOAAAwGguUgXbkQndqlVdUKMXP9QBAe0DYAdqRC92p9fkjd/u5GgBoHwg7wGWCs0IALleEHeAywVkhAJcrFigDAACjEXYAAIDRCDsAAMBohB0AAGA0wg4AADAad2MBaDNj029XZfWxZtsT4uNUuO4dP1YE4HJE2AFwURd6Rs+FAktl9bFmb3eXpNJXHvRJfQBwIYQdABd1oWf0EFgABDvW7AAAAKMRdgAAgNG4jAXgkrTVd26xuBmArxB2AFyStvrOLRY3wwQXCu0Edv8h7AAA0EYuFNoJ7P5D2AEQMG11CQwA/h5hB0DAtNUlsLbCOiKgfSLsAMCPdCnriFi7AQSOMWEnPz9fv/71r+VyuXT99dfrpZde0g033BDosgBAEms3gEAyIuz8/ve/V05OjpYvX64RI0bo+eefV1pamsrKyhQfHx/o8gAEEdMuRXHGKLAu9veJtWfBwYiw8+yzz2rGjBn6+c9/Lklavny51q1bp9dee00PP/xwgKsD0Bb4vq7vccbox2mrUHixv0/BuPbsctTuw86ZM2dUUlKi3Nxcz77Q0FClpqaquLi4yffU1dWprq7O87q2tlaS5Ha7fV5fQ0O9zn53qtl2q7Gx2fbWtgXqvZdTTZfTWIO1pvoGS33vfbLJtkO/fbTZ3+eL/U42NNS3+r1ffH5E/f9hRJNtX331tfo2894LfebFXKimSznuHXf/VK7/Pd5se1VlpewJCU22ObrF6u0//r5Vn9tWvqqsUnLm0022bVx0b7N/btKFx3Mp/8Zfyp/PhVzsz661fz7B+Hfi3PxZlnXhjlY79/XXX1uSrB07dnjtnzdvnnXDDTc0+Z4nnnjCksTGxsbGxsZmwFZRUXHBrNDuz+y0Rm5urnJycjyvGxsbdfz4ccXFxSkkJKTFx3O73UpKSlJFRYVsNpsvS71sMae+xXz6FvPpW8ynb11O82lZlk6cOKHExMQL9mv3Yadbt27q0KGDqqqqvPZXVVXJ4XA0+Z7IyEhFRkZ67YuJibnkWmw2m/F/sfyNOfUt5tO3mE/fYj5963KZz+jo6Iv2afffeh4REaGhQ4eqqKjIs6+xsVFFRUVyOp0BrAwAAASDdn9mR5JycnKUmZmpYcOG6YYbbtDzzz+vU6dOee7OAgAAly8jws5Pf/pT/fWvf9Xjjz8ul8ulwYMHa8OGDbLb7X75/MjISD3xxBPnXRpD6zGnvsV8+hbz6VvMp28xn+cLsayL3a8FAADQfrX7NTsAAAAXQtgBAABGI+wAAACjEXYAAIDRCDs+kJ+fr6uvvlodO3bUiBEj9NFHHwW6pKCTl5en4cOHq2vXroqPj9edd96psrIyrz6nT59WVlaW4uLi1KVLF2VkZJz3sMjy8nKlp6crKipK8fHxmjdvnurr6/05lKC0ePFihYSEaM6cOZ59zGfLff3117r33nsVFxenTp06aeDAgdqzZ4+n3bIsPf7440pISFCnTp2Umpqqzz77zOsYx48f15QpU2Sz2RQTE6Pp06fr5MmT/h5KwDU0NOixxx5Tr1691KlTJ/Xu3VtPPfWU13cYMZ/N27ZtmyZNmqTExESFhITorbfe8mr31dzt379fN998szp27KikpCQtWbKkrYcWGJf+7VSXt9WrV1sRERHWa6+9Zh08eNCaMWOGFRMTY1VVVQW6tKCSlpZmrVixwiotLbX27dtnTZw40erRo4d18uRJT5/777/fSkpKsoqKiqw9e/ZYI0eOtG688UZPe319vZWSkmKlpqZae/futdavX29169bNys3NDcSQgsZHH31kXX311dagQYOsBx54wLOf+WyZ48ePWz179rTuu+8+a9euXdbnn39ubdy40Tp8+LCnz+LFi63o6Gjrrbfesj7++GPr9ttvt3r16mV99913nj7jx4+3rr/+emvnzp3Whx9+aF177bXWPffcE4ghBdTTTz9txcXFWWvXrrWOHj1qvfHGG1aXLl2sF154wdOH+Wze+vXrrUcffdR68803LUnWmjVrvNp9MXe1tbWW3W63pkyZYpWWllqvv/661alTJ+u///u//TVMvyHsXKIbbrjBysrK8rxuaGiwEhMTrby8vABWFfyqq6stSdbWrVsty7KsmpoaKzw83HrjjTc8fT755BNLklVcXGxZ1ve//KGhoZbL5fL0WbZsmWWz2ay6ujr/DiBInDhxwurTp49VWFho/eQnP/GEHeaz5ebPn2/ddNNNzbY3NjZaDofD+vWvf+3ZV1NTY0VGRlqvv/66ZVmWdejQIUuStXv3bk+f9957zwoJCbG+/vrrtis+CKWnp1v/8i//4rXvrrvusqZMmWJZFvPZEj8MO76au5dfftm64oorvH7f58+fb/Xt27eNR+R/XMa6BGfOnFFJSYlSU1M9+0JDQ5Wamqri4uIAVhb8amtrJUmxsbGSpJKSEp09e9ZrLvv166cePXp45rK4uFgDBw70elhkWlqa3G63Dh486Mfqg0dWVpbS09O95k1iPlvjnXfe0bBhw/TP//zPio+P15AhQ/TKK6942o8ePSqXy+U1p9HR0RoxYoTXnMbExGjYsGGePqmpqQoNDdWuXbv8N5ggcOONN6qoqEh/+ctfJEkff/yxtm/frgkTJkhiPi+Fr+auuLhYt9xyiyIiIjx90tLSVFZWpr/97W9+Go1/GPEE5UD53//9XzU0NJz3pGa73a5PP/00QFUFv8bGRs2ZM0ejRo1SSkqKJMnlcikiIuK8L2S12+1yuVyePk3N9bm2y83q1av15z//Wbt37z6vjflsuc8//1zLli1TTk6OHnnkEe3evVu/+MUvFBERoczMTM+cNDVnfz+n8fHxXu1hYWGKjY297Ob04YcfltvtVr9+/dShQwc1NDTo6aef1pQpUySJ+bwEvpo7l8ulXr16nXeMc21XXHFFm9QfCIQd+F1WVpZKS0u1ffv2QJfSblVUVOiBBx5QYWGhOnbsGOhyjNDY2Khhw4bpmWeekSQNGTJEpaWlWr58uTIzMwNcXfvzhz/8QatWrVJBQYEGDBigffv2ac6cOUpMTGQ+4XdcxroE3bp1U4cOHc67w6WqqkoOhyNAVQW37OxsrV27Vh988IG6d+/u2e9wOHTmzBnV1NR49f/7uXQ4HE3O9bm2y0lJSYmqq6v1D//wDwoLC1NYWJi2bt2qF198UWFhYbLb7cxnCyUkJCg5OdlrX//+/VVeXi7p/+fkQr/vDodD1dXVXu319fU6fvz4ZTen8+bN08MPP6zJkydr4MCBmjp1qubOnau8vDxJzOel8NXcXU7/BhB2LkFERISGDh2qoqIiz77GxkYVFRXJ6XQGsLLgY1mWsrOztWbNGm3evPm8U6dDhw5VeHi411yWlZWpvLzcM5dOp1MHDhzw+gUuLCyUzWY77z8p040ZM0YHDhzQvn37PNuwYcM0ZcoUz8/MZ8uMGjXqvMch/OUvf1HPnj0lSb169ZLD4fCaU7fbrV27dnnNaU1NjUpKSjx9Nm/erMbGRo0YMcIPowge3377rUJDvf+L6dChgxobGyUxn5fCV3PndDq1bds2nT171tOnsLBQffv2NeoSliRuPb9Uq1evtiIjI62VK1dahw4dsmbOnGnFxMR43eECy5o1a5YVHR1tbdmyxaqsrPRs3377rafP/fffb/Xo0cPavHmztWfPHsvpdFpOp9PTfu5W6XHjxln79u2zNmzYYF155ZWX7a3SP/T3d2NZFvPZUh999JEVFhZmPf3009Znn31mrVq1yoqKirL+53/+x9Nn8eLFVkxMjPX2229b+/fvt+64444mb/cdMmSItWvXLmv79u1Wnz59LotbpX8oMzPTuuqqqzy3nr/55ptWt27drIceesjTh/ls3okTJ6y9e/dae/futSRZzz77rLV3717ryy+/tCzLN3NXU1Nj2e12a+rUqVZpaam1evVqKyoqilvP0bSXXnrJ6tGjhxUREWHdcMMN1s6dOwNdUtCR1OS2YsUKT5/vvvvO+vd//3friiuusKKioqx/+qd/siorK72O88UXX1gTJkywOnXqZHXr1s365S9/aZ09e9bPowlOPww7zGfLvfvuu1ZKSooVGRlp9evXz/rNb37j1d7Y2Gg99thjlt1utyIjI60xY8ZYZWVlXn2OHTtm3XPPPVaXLl0sm81m/fznP7dOnDjhz2EEBbfbbT3wwANWjx49rI4dO1rXXHON9eijj3rd5sx8Nu+DDz5o8t/MzMxMy7J8N3cff/yxddNNN1mRkZHWVVddZS1evNhfQ/SrEMv6u8dZAgAAGIY1OwAAwGiEHQAAYDTCDgAAMBphBwAAGI2wAwAAjEbYAQAARiPsAAAAoxF2AACA0Qg7AADAaIQdAABgNMIOAAAwGmEHAAAY7f8AqNSU6rISmpYAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_hist(df):\n",
    "    \"\"\" plot histplot of the code length \n",
    "    \"\"\"\n",
    "    len_arr = []\n",
    "    for i in range(len(df)):\n",
    "        len_arr.append(len(df.loc[i,'code']))\n",
    "    sns.histplot(len_arr)\n",
    "\n",
    "plot_hist(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('textstosequences', TextsToSequences()),\n",
      "                ('padder', Padder(maxlen=80)),\n",
      "                ('kerasclassifier',\n",
      "                 <keras.wrappers.scikit_learn.KerasClassifier object at 0x7f8791378040>)])\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 77\u001b[0m\n\u001b[1;32m     74\u001b[0m pipeline \u001b[39m=\u001b[39m make_pipeline(sequencer, padder, sklearn_lstm)\n\u001b[1;32m     76\u001b[0m \u001b[39mprint\u001b[39m(pipeline)\n\u001b[0;32m---> 77\u001b[0m pipeline\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n",
      "File \u001b[0;32m~/miniconda/envs/idetect/lib/python3.8/site-packages/sklearn/pipeline.py:402\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[39m\"\"\"Fit the model.\u001b[39;00m\n\u001b[1;32m    377\u001b[0m \n\u001b[1;32m    378\u001b[0m \u001b[39mFit all the transformers one after the other and transform the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[39m    Pipeline with fitted steps.\u001b[39;00m\n\u001b[1;32m    400\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    401\u001b[0m fit_params_steps \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_fit_params(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m--> 402\u001b[0m Xt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params_steps)\n\u001b[1;32m    403\u001b[0m \u001b[39mwith\u001b[39;00m _print_elapsed_time(\u001b[39m\"\u001b[39m\u001b[39mPipeline\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_log_message(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m)):\n\u001b[1;32m    404\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda/envs/idetect/lib/python3.8/site-packages/sklearn/pipeline.py:360\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[0;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[1;32m    358\u001b[0m     cloned_transformer \u001b[39m=\u001b[39m clone(transformer)\n\u001b[1;32m    359\u001b[0m \u001b[39m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[0;32m--> 360\u001b[0m X, fitted_transformer \u001b[39m=\u001b[39m fit_transform_one_cached(\n\u001b[1;32m    361\u001b[0m     cloned_transformer,\n\u001b[1;32m    362\u001b[0m     X,\n\u001b[1;32m    363\u001b[0m     y,\n\u001b[1;32m    364\u001b[0m     \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    365\u001b[0m     message_clsname\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mPipeline\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    366\u001b[0m     message\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_log_message(step_idx),\n\u001b[1;32m    367\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params_steps[name],\n\u001b[1;32m    368\u001b[0m )\n\u001b[1;32m    369\u001b[0m \u001b[39m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[1;32m    370\u001b[0m \u001b[39m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[1;32m    371\u001b[0m \u001b[39m# from the cache.\u001b[39;00m\n\u001b[1;32m    372\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[step_idx] \u001b[39m=\u001b[39m (name, fitted_transformer)\n",
      "File \u001b[0;32m~/miniconda/envs/idetect/lib/python3.8/site-packages/joblib/memory.py:349\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 349\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunc(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda/envs/idetect/lib/python3.8/site-packages/sklearn/pipeline.py:894\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[39mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[1;32m    893\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(transformer, \u001b[39m\"\u001b[39m\u001b[39mfit_transform\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 894\u001b[0m         res \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39;49mfit_transform(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m    895\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    896\u001b[0m         res \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m~/miniconda/envs/idetect/lib/python3.8/site-packages/sklearn/utils/_set_output.py:142\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    141\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 142\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    143\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    144\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    145\u001b[0m         \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    146\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    147\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    148\u001b[0m         )\n",
      "File \u001b[0;32m~/miniconda/envs/idetect/lib/python3.8/site-packages/sklearn/utils/_set_output.py:142\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    141\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 142\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    143\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    144\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    145\u001b[0m         \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    146\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    147\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    148\u001b[0m         )\n",
      "File \u001b[0;32m~/miniconda/envs/idetect/lib/python3.8/site-packages/sklearn/base.py:851\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    848\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n\u001b[1;32m    849\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    850\u001b[0m     \u001b[39m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m--> 851\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "Cell \u001b[0;32mIn[47], line 15\u001b[0m, in \u001b[0;36mTextsToSequences.fit\u001b[0;34m(self, texts, y)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, texts, y\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m---> 15\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit_on_texts(texts)\n\u001b[1;32m     16\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/miniconda/envs/idetect/lib/python3.8/site-packages/keras/preprocessing/text.py:293\u001b[0m, in \u001b[0;36mTokenizer.fit_on_texts\u001b[0;34m(self, texts)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    292\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39manalyzer \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 293\u001b[0m         seq \u001b[39m=\u001b[39m text_to_word_sequence(\n\u001b[1;32m    294\u001b[0m             text,\n\u001b[1;32m    295\u001b[0m             filters\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfilters,\n\u001b[1;32m    296\u001b[0m             lower\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlower,\n\u001b[1;32m    297\u001b[0m             split\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msplit,\n\u001b[1;32m    298\u001b[0m         )\n\u001b[1;32m    299\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    300\u001b[0m         seq \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39manalyzer(text)\n",
      "File \u001b[0;32m~/miniconda/envs/idetect/lib/python3.8/site-packages/keras/preprocessing/text.py:74\u001b[0m, in \u001b[0;36mtext_to_word_sequence\u001b[0;34m(input_text, filters, lower, split)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"Converts a text to a sequence of words (or tokens).\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \n\u001b[1;32m     48\u001b[0m \u001b[39mDeprecated: `tf.keras.preprocessing.text.text_to_word_sequence` does not\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[39m    A list of words (or tokens).\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[39mif\u001b[39;00m lower:\n\u001b[0;32m---> 74\u001b[0m     input_text \u001b[39m=\u001b[39m input_text\u001b[39m.\u001b[39;49mlower()\n\u001b[1;32m     76\u001b[0m translate_dict \u001b[39m=\u001b[39m {c: split \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m filters}\n\u001b[1;32m     77\u001b[0m translate_map \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m\u001b[39m.\u001b[39mmaketrans(translate_dict)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "\n",
    "\n",
    "seed = 101 # fix random seed for reproducibility\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "class TextsToSequences(Tokenizer, BaseEstimator, TransformerMixin):\n",
    "    \"\"\" Sklearn transformer to convert texts to indices list \n",
    "    (e.g. [[\"the cute cat\"], [\"the dog\"]] -> [[1, 2, 3], [1, 4]])\"\"\"\n",
    "    def __init__(self,  **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "    def fit(self, texts, y=None):\n",
    "        self.fit_on_texts(texts)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, texts, y=None):\n",
    "        return np.array(self.texts_to_sequences(texts))\n",
    "        \n",
    "sequencer = TextsToSequences(num_words=vocab_size)\n",
    "\n",
    "class Padder(BaseEstimator, TransformerMixin):\n",
    "    \"\"\" Pad and crop uneven lists to the same length. \n",
    "    Only the end of lists longernthan the maxlen attribute are\n",
    "    kept, and lists shorter than maxlen are left-padded with zeros\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    maxlen: int\n",
    "        sizes of sequences after padding\n",
    "    max_index: int\n",
    "        maximum index known by the Padder, if a higher index is met during \n",
    "        transform it is transformed to a 0\n",
    "    \"\"\"\n",
    "    def __init__(self, maxlen=500):\n",
    "        self.maxlen = maxlen\n",
    "        self.max_index = None\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        self.max_index = pad_sequences(X, maxlen=self.maxlen).max()\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X = pad_sequences(X, maxlen=self.maxlen)\n",
    "        X[X > self.max_index] = 0\n",
    "        return X\n",
    "\n",
    "padder = Padder(maxlen)\n",
    "\n",
    "def create_model(max_features):\n",
    "    \"\"\" Model creation function: returns a compiled LSTM\"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(max_features, 128))\n",
    "    model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "vocab_size = 20000  # Max number of different word, i.e. model input dimension\n",
    "maxlen = 80  # Max number of words kept at the end of each text\n",
    "batch_size = 128\n",
    "max_features = vocab_size + 1\n",
    "\n",
    "\n",
    "# Use Keras Scikit-learn wrapper to instantiate a LSTM with all methods\n",
    "# required by Scikit-learn for the last step of a Pipeline\n",
    "sklearn_lstm = KerasClassifier(build_fn=create_model, epochs=2, batch_size=batch_size, \n",
    "                               max_features=max_features, verbose=1)\n",
    "\n",
    "# Build the Scikit-learn pipeline\n",
    "pipeline = make_pipeline(sequencer, padder, sklearn_lstm)\n",
    "\n",
    "print(pipeline)\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'keras' has no attribute '___version__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mkeras\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m keras\u001b[39m.\u001b[39;49m___version__\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'keras' has no attribute '___version__'"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "keras.___version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras; \n",
    "if int(keras.__version__.split('.')[0])>=2:\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "idetect",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fafc45a6ddd39abcc5554869de579499dddcfa59fa9d77260344fc2dbb621709"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
