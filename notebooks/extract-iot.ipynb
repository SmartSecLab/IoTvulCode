{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Queries on CVE records for the extraction of IoT related referenced repositories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import json \n",
    "import ast\n",
    "import re\n",
    "import os\n",
    "import csv\n",
    "import subprocess\n",
    "import requests\n",
    "import tempfile\n",
    "from io import BytesIO, StringIO\n",
    "from zipfile import ZipFile\n",
    "from guesslang import Guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p_/9ryggq9s67zbhxhzlms6wmzw0000gn/T/ipykernel_24930/2247889250.py:1: DtypeWarning: Columns (7,8,9,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('../data/cve-records.csv')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/cve-records.csv')\n",
    "des_str = df['description'][0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search Query: \n",
    "\"Internet of Things\" OR \"IoT\" OR \"Industry 4.0\" OR \"smart cities\" OR \"smart city\"OR \"smart contract\" OR \"manufacturing\" OR \"energy\" OR \"supply chain\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count_cves: 2175\n"
     ]
    }
   ],
   "source": [
    "def get_description(des_str):\n",
    "    if des_str!=None or des_str!='':\n",
    "        des_arr_dict = ast.literal_eval(des_str)\n",
    "        des_cve = \"\"    #description of a CVE-> 'value' from array of dict.\n",
    "\n",
    "        for dic in des_arr_dict:\n",
    "            des_cve = des_cve + dic['value']\n",
    "        return des_cve\n",
    "        \n",
    "    else:\n",
    "        print('Empty description for CVE: ')\n",
    "        return 0\n",
    "\n",
    "def get_iot_cves(df):\n",
    "    iot_set = [\"Internet of Things\", \"IoT\", \"Industry 4.0\", \n",
    "                \"smart cities\", \"smart city\", \"smart contract\", \n",
    "                \"manufacturing\", \"energy\", \"supply chain\", \"orange pi\", \"banana pi\", \"arduino\"]\n",
    "    iot_cves = []\n",
    "\n",
    "    for row in range(len(df)):\n",
    "        des_cve = get_description(df['description'][row])\n",
    "        \n",
    "        # print if they are IoT related descriptions\n",
    "        for x in iot_set:\n",
    "            if x.lower() in des_cve.lower():\n",
    "                # print(des_cve)\n",
    "                # print(df['cve_id'][row])\n",
    "                iot_cves.append(df['cve_id'][row])\n",
    "                # print(df['reference_json'][row])\n",
    "                # print('\\n')\n",
    "    return iot_cves\n",
    "\n",
    "iot_cves = get_iot_cves(df)\n",
    "print('count_cves:', len(iot_cves))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2167"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_iot = df[df.cve_id.isin(iot_cves)]\n",
    "len(df_iot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "iot_vcs = ['github', 'bitbucket', 'gitlab']\n",
    "vcs_list = []\n",
    "\n",
    "for ref_str in df_iot.reference_json:\n",
    "    url_dict  = ast.literal_eval(ref_str)\n",
    "    \n",
    "    if len(url_dict) > 0:\n",
    "        for ref in url_dict:\n",
    "            vcs_list.append(ref['url'])     "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vulnerabilty reporting databases and number of their occurances in CVEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'url_heads' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m url_freq \u001b[39m=\u001b[39m collections\u001b[39m.\u001b[39mCounter(url_heads)\n\u001b[1;32m      2\u001b[0m df_url \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(url_freq\u001b[39m.\u001b[39mitems(), columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39murls\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mcount\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m      3\u001b[0m df_url \u001b[39m=\u001b[39m df_url\u001b[39m.\u001b[39msort_values(by\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mcount\u001b[39m\u001b[39m'\u001b[39m], ascending\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'url_heads' is not defined"
     ]
    }
   ],
   "source": [
    "url_freq = collections.Counter(url_heads)\n",
    "df_url = pd.DataFrame(url_freq.items(), columns=['urls', 'count'])\n",
    "df_url = df_url.sort_values(by=['count'], ascending=False)\n",
    "df_url.to_csv('../result/top-databases.csv', index=False, sep=';')\n",
    "df_url.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crawl project directories for source-code files and scan them for vulnerabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('../data/projects/contiki-2.4/tools'),\n",
       " PosixPath('../data/projects/contiki-2.4/.DS_Store'),\n",
       " PosixPath('../data/projects/contiki-2.4/core'),\n",
       " PosixPath('../data/projects/contiki-2.4/README-EXAMPLES'),\n",
       " PosixPath('../data/projects/contiki-2.4/cpu'),\n",
       " PosixPath('../data/projects/contiki-2.4/platform'),\n",
       " PosixPath('../data/projects/contiki-2.4/README-BUILDING'),\n",
       " PosixPath('../data/projects/contiki-2.4/README'),\n",
       " PosixPath('../data/projects/contiki-2.4/examples'),\n",
       " PosixPath('../data/projects/contiki-2.4/Makefile.include'),\n",
       " PosixPath('../data/projects/contiki-2.4/doc'),\n",
       " PosixPath('../data/projects/contiki-2.4/apps')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pathlib\n",
    "from os import walk\n",
    "\n",
    "prj_dir = '../data/projects/contiki-2.4/'\n",
    "\n",
    "[p for p in pathlib.Path(prj_dir).iterdir()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files in the project:  1992\n"
     ]
    }
   ],
   "source": [
    "def get_filepaths(directory):\n",
    "    \"\"\"\n",
    "    This function will generate the file names in a directory \n",
    "    tree by walking the tree either top-down or bottom-up. For each \n",
    "    directory in the tree rooted at directory top (including top itself), \n",
    "    it yields a 3-tuple (dirpath, dirnames, filenames).\n",
    "    # ref: https://stackoverflow.com/questions/3207219/how-do-i-list-all-files-of-a-directory\n",
    "    \"\"\"\n",
    "    file_paths = []  # List which will store all of the full filepaths.\n",
    "\n",
    "    # Walk the tree.\n",
    "    for root, directories, files in os.walk(directory):\n",
    "        for filename in files:\n",
    "            # Join the two strings in order to form the full filepath.\n",
    "            filepath = os.path.join(root, filename)\n",
    "            file_paths.append(filepath)  # Add it to the list.\n",
    "\n",
    "    return file_paths  # Self-explanatory.\n",
    "\n",
    "prj_files = get_filepaths(prj_dir)\n",
    "print('Number of files in the project: ', len(prj_files))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetching list of C/C++ files from zip file of the project url. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guess programming language and scan only C programs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_internet(url):\n",
    "    response = requests.get(url)\n",
    "    return True if response.status_code < 400 else False\n",
    "    \n",
    "    \n",
    "def retrieve_zip(url):\n",
    "    \"\"\" Fetching list of C/C++ files from zip file of the project url. \n",
    "    \"\"\"\n",
    "    if check_internet(url):\n",
    "        r = requests.get(url)\n",
    "        # BytesIO keeps the file in memory\n",
    "        return ZipFile(io.BytesIO(r.content))  \n",
    "    else:\n",
    "        print('Internet is not working!')\n",
    "        return None\n",
    "\n",
    "\n",
    "def guess_pl(file, zip_obj=None):\n",
    "    \"\"\" guess programming language of the input file. \n",
    "    \"\"\" \n",
    "    guess = Guess()\n",
    "    if zip_obj is not None:\n",
    "        # extract a specific file from the zip container\n",
    "        with zip_obj.open(file, 'r') as f:\n",
    "            lang = guess.language_name(f.read())\n",
    "    else:\n",
    "        with open(file, 'r', encoding= 'unicode_escape') as f:\n",
    "            lang = guess.language_name(f.read())\n",
    "    return lang\n",
    "\n",
    "# # Example code:\n",
    "# file = '../data/projects/contiki-2.4/tools/tunslip.c'\n",
    "# path = '../data/projects/contiki-2.4/tools/'\n",
    "# # cmd = 'flawfinder --csv --inputs ' + path + ' >> output.csv'\n",
    "# cmd = 'flawfinder --csv --inputs ' + path\n",
    "# process = subprocess.Popen(cmd,  shell=True, stdout=subprocess.PIPE)\n",
    "# output = process.stdout.read()\n",
    "# df=pd.read_csv(StringIO(str(output,'utf-8')))\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'io' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 47\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[39mreturn\u001b[39;00m df\n\u001b[1;32m     46\u001b[0m url  \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mhttps://sourceforge.net/projects/contiki/files/Contiki/Contiki\u001b[39m\u001b[39m%\u001b[39m\u001b[39m202.4/contiki-sky-2.4.zip/download\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m---> 47\u001b[0m zipobj \u001b[39m=\u001b[39m retrieve_zip(url)\n\u001b[1;32m     49\u001b[0m files \u001b[39m=\u001b[39m zipobj\u001b[39m.\u001b[39mnamelist() \n\u001b[1;32m     50\u001b[0m selected_files \u001b[39m=\u001b[39m [x \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m files \u001b[39mif\u001b[39;00m guess_pl(x, zipobj) \u001b[39min\u001b[39;00m [\u001b[39m'\u001b[39m\u001b[39mC\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mC++\u001b[39m\u001b[39m'\u001b[39m]]\n",
      "Cell \u001b[0;32mIn[8], line 12\u001b[0m, in \u001b[0;36mretrieve_zip\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m     10\u001b[0m     r \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39mget(url)\n\u001b[1;32m     11\u001b[0m     \u001b[39m# BytesIO keeps the file in memory\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m     \u001b[39mreturn\u001b[39;00m ZipFile(io\u001b[39m.\u001b[39mBytesIO(r\u001b[39m.\u001b[39mcontent))  \n\u001b[1;32m     13\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mInternet is not working!\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'io' is not defined"
     ]
    }
   ],
   "source": [
    "def find_flaw(file_or_dir):\n",
    "    \"\"\" find flaws ini the file using flawfinder tool\n",
    "    return : flawfinder output as a CSV file.\n",
    "    Usage: cmd = 'flawfinder --csv --inputs ' + path + ' >> output.csv'\n",
    "    \"\"\"\n",
    "    if os.path.isfile(file_or_dir):\n",
    "        cmd = 'flawfinder --csv ' + file_or_dir\n",
    "    elif ps.path.isdir(file_or_dir):\n",
    "        cmd = 'flawfinder --csv --inputs ' + file_or_dir\n",
    "        \n",
    "    process = subprocess.Popen(cmd,  shell=True, stdout=subprocess.PIPE)\n",
    "    output = process.stdout.read()\n",
    "    return pd.read_csv(StringIO(str(output,'utf-8')))\n",
    "    \n",
    "\n",
    "def file2df(file, zip_obj=None):\n",
    "    \"\"\" convert zipped file stream - tempfile to pandas dataframe. \n",
    "    \"\"\"\n",
    "    file_content = ''\n",
    "    \n",
    "    if zip_obj:\n",
    "        # io.StringIO(sf.read().decode(\"utf-8\")).read()\n",
    "        with zip_obj.open(file) as fc:\n",
    "            # file_content = fc.read().encode('UTF-8')\n",
    "            file_content = fc.read()\n",
    "    else:\n",
    "        with open(file) as fc:\n",
    "            file_content = fc.read().encode('UTF-8')\n",
    "\n",
    "    fp = tempfile.NamedTemporaryFile(suffix='_Flawfinder',\n",
    "                                    prefix='Filename_')\n",
    "    # deal with the temp file of extracted zipped file\n",
    "    try:\n",
    "        fp.write(file_content)\n",
    "        fp.seek(0)  # move reader's head to the initial point of the file. \n",
    "        file_name = fp.name\n",
    "        df = find_flaw(file_name)\n",
    "    except OSError:\n",
    "        print(\"Could not open/read file:\", fp)\n",
    "        sys.exit(1)\n",
    "    finally:\n",
    "        fp.close()\n",
    "    return df\n",
    "\n",
    "\n",
    "url  = 'https://sourceforge.net/projects/contiki/files/Contiki/Contiki%202.4/contiki-sky-2.4.zip/download'\n",
    "zipobj = retrieve_zip(url)\n",
    "\n",
    "files = zipobj.namelist() \n",
    "selected_files = [x for x in files if guess_pl(x, zipobj) in ['C', 'C++']]\n",
    "# concatenate all the output dataframes of all the files\n",
    "df_composite = pd.concat([file2df(selected_files[i], zipobj) for i in range(len(selected_files))])\n",
    "print(df_composite.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'retrieve_zip' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m zipobj \u001b[39m=\u001b[39m retrieve_zip(url)\n\u001b[1;32m      3\u001b[0m files \u001b[39m=\u001b[39m zipobj\u001b[39m.\u001b[39mnamelist() \n\u001b[1;32m      4\u001b[0m selected_files \u001b[39m=\u001b[39m [x \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m files \u001b[39mif\u001b[39;00m guess_pl(x, zipobj) \u001b[39min\u001b[39;00m [\u001b[39m'\u001b[39m\u001b[39mC\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mC++\u001b[39m\u001b[39m'\u001b[39m]]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'retrieve_zip' is not defined"
     ]
    }
   ],
   "source": [
    "zipobj = retrieve_zip(url)\n",
    "\n",
    "files = zipobj.namelist() \n",
    "selected_files = [x for x in files if guess_pl(x, zipobj) in ['C', 'C++']]\n",
    "# concatenate all the output dataframes of all the files\n",
    "df_composite = pd.concat([file2df(selected_files[i], zipobj) for i in range(len(selected_files))])\n",
    "print(df_composite.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving prj url to a folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from zipfile import ZipFile\n",
    "\n",
    "url  = 'https://sourceforge.net/projects/contiki/files/Contiki/Contiki%202.4/contiki-sky-2.4.zip/download'\n",
    "\n",
    "zipresp = urlopen(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<http.client.HTTPResponse at 0x7f8c20356070>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zipresp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iotCode",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2f838046bc7a32c7f2766f1c532b5baddca8fb3dd7100bdb4fa26065ff771de8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
